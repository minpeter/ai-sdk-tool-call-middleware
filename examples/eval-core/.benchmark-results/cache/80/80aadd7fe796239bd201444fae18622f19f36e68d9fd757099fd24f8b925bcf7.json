{
  "type": "generate",
  "content": [
    {
      "type": "tool-call",
      "toolCallId": "bwul13bg0bh",
      "toolName": "calculate_average",
      "input": "{\"gradeDict\":{\"math\":90,\"science\":75,\"history\":82,\"music\":89}}"
    }
  ],
  "finishReason": { "unified": "stop", "raw": "stop" },
  "usage": {
    "inputTokens": { "total": 741, "noCache": 741, "cacheRead": 0 },
    "outputTokens": { "total": 51, "text": 51, "reasoning": 0 },
    "raw": {
      "prompt_tokens": 741,
      "completion_tokens": 51,
      "total_tokens": 792
    }
  },
  "warnings": [],
  "response": {
    "id": "chatcmpl-3d6ff649e27d478090de3b01da504b61",
    "modelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
    "timestamp": "2026-01-01T19:32:56.000Z",
    "headers": {
      "access-control-allow-credentials": "true",
      "connection": "keep-alive",
      "content-length": "503",
      "content-type": "application/json",
      "date": "Thu, 01 Jan 2026 19:32:56 GMT",
      "server": "envoy",
      "vary": "Origin",
      "x-envoy-upstream-service-time": "788",
      "x-friendli-lb-weight": "2",
      "x-ratelimit-limit-requests": "100",
      "x-ratelimit-remaining-requests": "94",
      "x-ratelimit-reset-requests": "57"
    },
    "body": {
      "choices": [
        {
          "finish_reason": "stop",
          "index": 0,
          "logprobs": null,
          "message": {
            "content": "<calculate_average>\n  <gradeDict>\n    <math>90</math>\n    <science>75</science>\n    <history>82</history>\n    <music>89</music>\n  </gradeDict>\n</calculate_average>",
            "role": "assistant"
          }
        }
      ],
      "created": 1767295976,
      "id": "chatcmpl-3d6ff649e27d478090de3b01da504b61",
      "model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "object": "chat.completion",
      "usage": {
        "completion_tokens": 51,
        "prompt_tokens": 741,
        "total_tokens": 792
      }
    }
  },
  "providerMetadata": { "friendli": {} },
  "request": {
    "body": "{\"model\":\"meta-llama/Llama-4-Maverick-17B-128E-Instruct\",\"max_tokens\":256,\"temperature\":0,\"messages\":[{\"role\":\"user\",\"content\":\"Calculate the average grade for student John who has these scores {'math':90, 'science':75, 'history':82, 'music':89} across different subjects.\"},{\"role\":\"system\",\"content\":\"You are an AI assistant capable of executing tool calls.\\n\\n# Tool Definitions\\nThe available tools are defined below in JSON Schema format.\\n<tools>\\n[{\\\"name\\\":\\\"calculate_standard_deviation\\\",\\\"description\\\":\\\"This function calculates the standard deviation across different scores for a specific student.\\\",\\\"parameters\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"gradeDict\\\":{\\\"type\\\":\\\"object\\\",\\\"description\\\":\\\"A dictionary where keys represent subjects and values represent scores\\\"}},\\\"required\\\":[\\\"gradeDict\\\"]}},{\\\"name\\\":\\\"calculate_average\\\",\\\"description\\\":\\\"This function calculates the average grade across different subjects for a specific student.\\\",\\\"parameters\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"gradeDict\\\":{\\\"type\\\":\\\"object\\\",\\\"description\\\":\\\"A dictionary where keys represent subjects and values represent scores\\\"}},\\\"required\\\":[\\\"gradeDict\\\"]}},{\\\"name\\\":\\\"highest_grade\\\",\\\"description\\\":\\\"This function finds the subject where the student got the highest score.\\\",\\\"parameters\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"gradeDict\\\":{\\\"type\\\":\\\"object\\\",\\\"description\\\":\\\"A dictionary where keys represent subjects and values represent scores\\\"}},\\\"required\\\":[\\\"gradeDict\\\"]}}]\\n</tools>\\n\\n# Instructions\\n1. **Output Format**: Use XML.\\n   - `<tool_name><param1>value1</param1>...</tool_name>`\\n2. **Parameter Names**: You MUST use the **EXACT** parameter names from the JSON schema.\\n   - ðŸ”´ BAD: `<turns_per_meter>...</turns_per_meter>` (if schema says `turnsPerMeter`)\\n   - ðŸŸ¢ GOOD: `<turnsPerMeter>...</turnsPerMeter>`\\n   - ðŸ”´ BAD: `<from>...</from>` (if schema says `_from`)\\n   - ðŸŸ¢ GOOD: `<_from>...</_from>`\\n   - ðŸ”´ BAD: `<airline>...</airline>` (if schema says `airlines`)\\n   - ðŸŸ¢ GOOD: `<airlines>...</airlines>`\\n3. **Parameter Values**:\\n   - Keep numbers as numbers (e.g. `0.05` should not become `5`).\\n   - Keep strings as strings.\\n   - Do NOT wrap JSON objects in extra XML tags unless necessary.\\n4. **Call Count**:\\n   - Call ONLY the functions explicitly requested by the user.\\n   - Do NOT output multiple variations of the same call.\\n   - Do NOT output \\\"thought\\\" or \\\"reasoning\\\".\\n   - **STOP generating immediately after the closing tag of the last function call.**\\n\\n# Examples\\n\\n## CamelCase Parameter Preservation\\nSchema: `motor_control(speedInRPM, max_current)`\\nUser: Set speed to 1000 and max current to 5.\\nModel:\\n<motor_control>\\n  <speedInRPM>1000</speedInRPM>\\n  <max_current>5</max_current>\\n</motor_control>\\n\\n## Underscore Parameter Preservation\\nSchema: `search(_from, to)`\\nUser: Search from A to B.\\nModel:\\n<search>\\n  <_from>A</_from>\\n  <to>B</to>\\n</search>\\n\\n## Exact Number Preservation\\nSchema: `set_rate(rate)`\\nUser: Set rate to 5%.\\nModel:\\n<set_rate>\\n  <rate>0.05</rate>\\n</set_rate>\\n\\n## Multiple Calls (Sequential)\\nUser: Get weather in NY and LA.\\nModel:\\n<get_weather>\\n  <location>NY</location>\\n</get_weather>\\n<get_weather>\\n  <location>LA</location>\\n</get_weather>\\n\"}]}"
  }
}
