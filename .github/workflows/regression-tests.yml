name: Regression Tests

on:
  # ìˆ˜ë™ íŠ¸ë¦¬ê±°
  workflow_dispatch:
    inputs:
      benchmark_mode:
        description: 'Benchmark mode'
        required: false
        default: 'fast'
        type: choice
        options:
          - fast           # 4 categories x 5 cases (~2min)
          - full           # all cases (~15min)

  # PR ëŒ“ê¸€ íŠ¸ë¦¬ê±°
  issue_comment:
    types: [created]

  # PR ìƒì„± ë° ì»¤ë°‹ ì¶”ê°€ ì‹œ ìë™ ì‹¤í–‰ (fast ëª¨ë“œ)
  pull_request:
    types: [opened, synchronize]
    paths:
      - 'packages/parser/**'
      - 'packages/eval/**'
      - 'packages/middleware/**'

  # mainì— ë¨¸ì§€ë  ë•Œ fast ëª¨ë“œë¡œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (ë² ì´ìŠ¤ë¼ì¸ ì¶•ì )
  push:
    branches:
      - main
    paths:
      - 'packages/parser/**'
      - 'packages/eval/**'
      - 'packages/middleware/**'

permissions:
  contents: write
  pull-requests: write
  id-token: write

# Concurrency ì „ëµ:
# - PR ì´ë²¤íŠ¸: ìµœì‹  ì»¤ë°‹ë§Œ ë‚¨ê¸°ê³  ì´ì „ ì‹¤í–‰ ì·¨ì†Œ (ë¹„ìš© ì ˆê°)
# - main push: ì·¨ì†Œí•˜ì§€ ì•Šê³  íë¡œ ì§ë ¬ ì‹¤í–‰ (ê° runì´ historyì— ëˆ„ì ë˜ë„ë¡)
concurrency:
  group: >-
    ${{ github.workflow }}-${{
      (github.event_name == 'push' && github.ref == 'refs/heads/main')
      && 'main-benchmark-queue'
      || (github.event.pull_request.number || github.ref)
    }}
  cancel-in-progress: ${{ github.event_name != 'push' || github.ref != 'refs/heads/main' }}

jobs:
  # ëŒ“ê¸€ íŒŒì‹± ë° ëª¨ë“œ ê²°ì •
  parse-comment:
    name: Parse Comment Command
    runs-on: ubuntu-latest
    if: github.event_name == 'issue_comment'
    outputs:
      should_run: ${{ steps.parse.outputs.should_run }}
      mode: ${{ steps.parse.outputs.mode }}
      pr_number: ${{ steps.parse.outputs.pr_number }}
      comment_id: ${{ steps.parse.outputs.comment_id }}
    steps:
      - name: Parse comment
        id: parse
        uses: actions/github-script@v8
        with:
          script: |
            const comment = context.payload.comment.body.toLowerCase();
            const isPR = !!context.payload.issue.pull_request;

            // PR ëŒ“ê¸€ë§Œ ì²˜ë¦¬
            if (!isPR) {
              core.setOutput('should_run', 'false');
              return;
            }

            // ëª…ë ¹ì–´ íŒŒì‹±
            let mode = 'fast';
            let shouldRun = false;

            if (comment.includes('/benchmark')) {
              shouldRun = true;

              if (comment.includes('full') || comment.includes('all')) {
                mode = 'full';
              } else {
                mode = 'fast';
              }

              // ğŸ‘€ ì´ëª¨ì§€ ë¦¬ì•¡ì…˜ ì¶”ê°€
              await github.rest.reactions.createForIssueComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: context.payload.comment.id,
                content: 'eyes'
              });
            }

            core.setOutput('should_run', shouldRun.toString());
            core.setOutput('mode', mode);
            core.setOutput('pr_number', context.issue.number.toString());
            core.setOutput('comment_id', context.payload.comment.id.toString());

  regression-benchmarks:
    name: Run Regression Benchmarks
    timeout-minutes: 30
    runs-on: ubuntu-latest
    needs: [parse-comment]
    # ë¬´í•œ ë£¨í”„ ë°©ì§€: [skip benchmarks] í† í°ì´ ì»¤ë°‹ ë©”ì‹œì§€ì— ìˆìœ¼ë©´ push ì´ë²¤íŠ¸ ìŠ¤í‚µ
    # paths í•„í„°ê°€ .benchmark-resultsë¥¼ í¬í•¨í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ 1ì°¨ ë°©ì–´ëŠ” ì´ë¯¸ ë˜ì–´ ìˆìŒ
    # ì´ ì¡°ê±´ì€ 2ì°¨ ë°©ì–´ì¸µìœ¼ë¡œ, í˜¹ì‹œ pathsê°€ ë³€ê²½ë˜ë”ë¼ë„ ì•ˆì „í•˜ê²Œ ë™ì‘
    if: |
      always() && (
        (github.event_name == 'push' && !contains(github.event.head_commit.message, '[skip benchmarks]')) ||
        github.event_name == 'workflow_dispatch' ||
        github.event_name == 'pull_request' ||
        (github.event_name == 'issue_comment' && needs.parse-comment.outputs.should_run == 'true')
      )

    steps:
      - name: Get PR ref (for comment trigger)
        id: get-pr-ref
        if: github.event_name == 'issue_comment'
        uses: actions/github-script@v8
        with:
          script: |
            const pr = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });
            core.setOutput('ref', pr.data.head.ref);
            core.setOutput('sha', pr.data.head.sha);

      - name: Checkout
        uses: actions/checkout@v6
        with:
          ref: ${{ github.event_name == 'issue_comment' && steps.get-pr-ref.outputs.ref || '' }}
          fetch-depth: 0

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Use Node.js 22
        uses: actions/setup-node@v6
        with:
          node-version: 22
          cache: pnpm

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build packages
        run: pnpm build

      - name: Determine benchmark mode
        id: mode
        run: |
          MODE="${{
            github.event_name == 'workflow_dispatch' && github.event.inputs.benchmark_mode ||
            (github.event_name == 'issue_comment' && needs.parse-comment.outputs.mode) ||
            'fast'
          }}"
          echo "mode=$MODE" >> $GITHUB_OUTPUT
          echo "Running in $MODE mode"

      # main push ì‹œ: ê¸°ì¡´ ê²°ê³¼ ë¸Œëœì¹˜ì˜ history.jsonlì„ ë¨¼ì € ê°€ì ¸ì™€ì„œ ëˆ„ì  ë³´ì¥
      - name: Fetch existing benchmark history (main push only)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          # ê²°ê³¼ ë¸Œëœì¹˜ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
          if git ls-remote --exit-code --heads origin ci/benchmark-results > /dev/null 2>&1; then
            echo "Fetching existing history from ci/benchmark-results branch..."
            git fetch origin ci/benchmark-results:ci/benchmark-results
            # ê¸°ì¡´ history.jsonlì„ í˜„ì¬ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ë³µì‚¬
            git show ci/benchmark-results:.benchmark-results/history.jsonl > .benchmark-results/history.jsonl 2>/dev/null || true
            echo "Existing history fetched successfully"
          else
            echo "No existing benchmark results branch found, starting fresh"
          fi

      - name: Run regression benchmarks
        id: benchmark
        env:
          FRIENDLI_TOKEN: ${{ secrets.FRIENDLI_TOKEN || vars.FRIENDLI_TOKEN }}
          BENCHMARK_MODE: ${{ steps.mode.outputs.mode }}
        run: |
          pnpm ci:benchmark
        continue-on-error: true

      - name: Compare with historical data
        id: compare
        if: steps.benchmark.outcome == 'success'
        run: |
          pnpm ci:compare
        continue-on-error: true

      # PR/issue_comment ì´ë²¤íŠ¸: ê¸°ì¡´ì²˜ëŸ¼ í•´ë‹¹ ë¸Œëœì¹˜ì— ì§ì ‘ push
      - name: Commit and push benchmark results (PR/comment)
        if: |
          steps.benchmark.outcome == 'success' &&
          (github.event_name == 'pull_request' || github.event_name == 'issue_comment')
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add .benchmark-results/history.jsonl

          if ! git diff --quiet --cached; then
            git commit -m "ci: add benchmark results for ${{ github.sha }}"

            if [ "${{ github.event_name }}" = "pull_request" ]; then
              git push origin HEAD:${{ github.head_ref }}
            elif [ "${{ github.event_name }}" = "issue_comment" ]; then
              git push origin HEAD:${{ steps.get-pr-ref.outputs.ref }}
            fi
          fi
        continue-on-error: true

      # main push ì´ë²¤íŠ¸: PRì„ í†µí•´ ê²°ê³¼ ì €ì¥ (ë¸Œëœì¹˜ ë³´í˜¸ ê·œì¹™ ì¤€ìˆ˜)
      - name: Create benchmark results PR (main push only)
        if: |
          steps.benchmark.outcome == 'success' &&
          github.event_name == 'push' &&
          github.ref == 'refs/heads/main'
        env:
          GH_TOKEN: ${{ github.token }}
          COMMIT_SHA: ${{ github.sha }}
          WORKFLOW_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          git add .benchmark-results/history.jsonl
          if git diff --quiet --cached; then
            echo "No changes to commit"
            exit 0
          fi

          BRANCH_NAME="ci/benchmark-results"
          
          git checkout -B "$BRANCH_NAME"
          git commit -m "ci: add benchmark results for ${COMMIT_SHA} [skip benchmarks]"
          git push -f origin "$BRANCH_NAME"
          
          EXISTING_PR=$(gh pr list --head "$BRANCH_NAME" --base main --state open --json number --jq '.[0].number' || echo "")
          TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
          
          PR_BODY="## Benchmark Results Update

          This PR contains automatically generated benchmark results.

          **Latest commit:** \`${COMMIT_SHA}\`
          **Updated:** ${TIMESTAMP}
          **Workflow run:** ${WORKFLOW_URL}

          ---

          > **Note**: This PR is automatically managed by the regression test workflow.
          > Merging this PR will NOT trigger another benchmark run (protected by \`[skip benchmarks]\` token and path filters).
          > 
          > The benchmark history will continue to accumulate even if this PR is not merged immediately."
          
          if [ -n "$EXISTING_PR" ] && [ "$EXISTING_PR" != "null" ]; then
            echo "Existing PR #$EXISTING_PR found, updating..."
            echo "$PR_BODY" | gh pr edit "$EXISTING_PR" --body-file -
          else
            echo "Creating new PR..."
            echo "$PR_BODY" | gh pr create \
              --title "ci: update benchmark history [skip benchmarks]" \
              --body-file - \
              --head "$BRANCH_NAME" \
              --base main
          fi

      - name: Comment PR with benchmark failure
        if: |
          (github.event_name == 'issue_comment' || github.event_name == 'pull_request') &&
          steps.benchmark.outcome == 'failure'
        uses: actions/github-script@v8
        with:
          script: |
            const issueNumber = context.issue?.number ||
                                context.payload.pull_request?.number ||
                                ${{ needs.parse-comment.outputs.pr_number || 0 }};

            if (!issueNumber) return;

            const sha = '${{ github.sha }}';
            const mode = '${{ steps.mode.outputs.mode }}';
            const logsUrl = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';

            const body = '## âŒ Benchmark Execution Failed\n\n' +
              '**Commit:** `' + sha + '`\n' +
              '**Mode:** ' + mode + '\n\n' +
              'The benchmark execution failed. This could be due to:\n' +
              '- Missing API token (FRIENDLI_TOKEN)\n' +
              '- Network issues\n' +
              '- Model availability issues\n' +
              '- Code compilation errors\n\n' +
              'Please check the [workflow logs](' + logsUrl + ') for more details.';

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: body,
            });

            // ì‹¤íŒ¨ ì‹œ âŒ ë¦¬ì•¡ì…˜ ì¶”ê°€ (ëŒ“ê¸€ íŠ¸ë¦¬ê±°ì¸ ê²½ìš°)
            const commentId = '${{ needs.parse-comment.outputs.comment_id }}';
            if (commentId) {
              await github.rest.reactions.createForIssueComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: parseInt(commentId),
                content: '-1'
              });
            }

      - name: Comment PR with results
        if: |
          (github.event_name == 'issue_comment' || github.event_name == 'pull_request') &&
          steps.compare.outcome == 'success'
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // Read report from file
            const reportPath = path.join(process.cwd(), '.benchmark-results/report.md');
            if (!fs.existsSync(reportPath)) {
              console.log('No report file found');
              return;
            }

            const report = fs.readFileSync(reportPath, 'utf8');

            const issueNumber = context.issue?.number ||
                                context.payload.pull_request?.number ||
                                ${{ needs.parse-comment.outputs.pr_number || 0 }};

            if (!issueNumber) return;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Regression Benchmark Results')
            );

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: report,
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: report,
              });
            }

            // ì„±ê³µ ì‹œ ğŸš€ ë¦¬ì•¡ì…˜ ì¶”ê°€ (ëŒ“ê¸€ íŠ¸ë¦¬ê±°ì¸ ê²½ìš°)
            const commentId = '${{ needs.parse-comment.outputs.comment_id }}';
            if (commentId) {
              await github.rest.reactions.createForIssueComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: parseInt(commentId),
                content: 'rocket'
              });
            }

      - name: Upload benchmark results as artifact
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: benchmark-results-${{ github.sha }}
          path: .benchmark-results/
          retention-days: 90

      - name: Fail if regression detected
        if: steps.benchmark.outcome == 'success' && steps.compare.outcome == 'failure'
        run: |
          echo "::error::Performance regression detected. See PR comment for details."
          exit 1

      - name: Fail if benchmark execution failed
        if: steps.benchmark.outcome == 'failure'
        run: |
          echo "::error::Benchmark execution failed. Please check the logs for details."
          exit 1
