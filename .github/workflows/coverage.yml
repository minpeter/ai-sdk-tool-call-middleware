name: Coverage Upload

on:
  push:
    branches: [main]
  pull_request:

jobs:
  coverage:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: "pnpm"

      - name: Install
        run: pnpm install --frozen-lockfile

      - name: Build
        run: pnpm build

      - name: Run tests (auto-detect, parallel, coverage when supported)
        run: |
          set -euo pipefail
          echo "Detecting workspace packages with package.json under packages/ and examples/..."
          mapfile -t PKGS < <(find packages examples -maxdepth 2 -type f -name package.json 2>/dev/null || true)
          if [ ${#PKGS[@]} -eq 0 ]; then
            echo "No workspace packages found. Exiting."
            exit 0
          fi

          cmds=()
          for PJ in "${PKGS[@]}"; do
            DIR=$(dirname "$PJ")
            NAME=$(node -e "const fs=require('fs'); const p=JSON.parse(fs.readFileSync(process.argv[1],'utf8')); console.log(p.name||'')" "$PJ")
            TEST_SCRIPT=$(node -e "const fs=require('fs'); const p=JSON.parse(fs.readFileSync(process.argv[1],'utf8')); console.log((p.scripts&&p.scripts.test)||'')" "$PJ")
            HAS_VITEST=0
            # detect vitest by test script or dependencies
            if echo "$TEST_SCRIPT" | grep -qi "vitest"; then
              HAS_VITEST=1
            else
              node -e "const fs=require('fs');const p=JSON.parse(fs.readFileSync(process.argv[1],'utf8')); const deps=Object.assign({},p.dependencies||{},p.devDependencies||{}); const has=Object.keys(deps).some(k=>/vitest/i.test(k)); process.exit(has?0:1)" "$PJ" && HAS_VITEST=1 || HAS_VITEST=${HAS_VITEST}
            fi

            if [ "$HAS_VITEST" -eq 1 ]; then
              echo "Will run with coverage: $NAME"
              cmds+=("pnpm --filter \"$NAME\" run test -- --coverage")
            else
              echo "Will run without coverage: $NAME"
              cmds+=("pnpm --filter \"$NAME\" run test")
            fi
          done

          # run commands in parallel with a concurrency limit
          MAX=4
          running=0
          for c in "${cmds[@]}"; do
            echo "Starting: $c"
            bash -lc "$c" &
            running=$((running+1))
            if [ "$running" -ge "$MAX" ]; then
              wait -n || true
              running=$((running-1))
            fi
          done
          wait || true

      - name: Merge LCOV files
        run: |
          echo "Merging LCOV files into ./coverage/lcov.info"
          mkdir -p coverage
          # Use pnpm dlx to run lcov-result-merger; fallback to concatenation if unavailable
          if pnpm -v >/dev/null 2>&1; then
            pnpm dlx -y lcov-result-merger "**/coverage/lcov.info" -o coverage/lcov.info || true
          fi
          # if merger didn't create merged file, try a safe concat fallback
          if [ ! -f coverage/lcov.info ]; then
            echo "Falling back to simple concatenation for LCOV files"
            find . -type f -name lcov.info -print0 | xargs -0 cat > coverage/lcov.info || true
          fi
          echo "Merged file size: $(stat -c%s coverage/lcov.info || echo 0)"

      - name: List generated coverage files (debug)
        run: |
          echo "Searching for coverage files"
          find . -type f -name lcov.info || true
          echo "Listing coverage directories"
          find . -type d -name coverage -maxdepth 4 -print -exec ls -la {} \; || true

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: |
            coverage/lcov.info
            **/coverage/lcov.info
          fail_ci_if_error: false

      - name: Note about protected branches
        run: |
          echo "If upload fails on protected branches, add CODECOV_TOKEN to repository secrets and re-run the workflow."
